{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gWTHyM0m85S6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import (Input, Add, Dense, Activation, ZeroPadding2D, Flatten, Conv2D,\n",
    "                                     AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,\n",
    "                                     BatchNormalization,Dropout)\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "# from resnets_utils import *\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XBlcldCx9tJz",
    "outputId": "eafb65fa-6118-409c-b926-ae97e7075724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 872 files belonging to 5 classes.\n",
      "Using 698 files for training.\n",
      "Found 872 files belonging to 5 classes.\n",
      "Using 174 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# 1024\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "pixes = 512\n",
    "IMG_SIZE = (pixes, pixes)\n",
    "directory = './train_images'\n",
    "train_dataset = image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                            #  image_size=IMG_SIZE,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='training',\n",
    "                                             seed=42)\n",
    "validation_dataset = image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                            #  image_size=IMG_SIZE,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='validation',\n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O5FRrXYBK4yJ"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "sH07vCFT_pZo"
   },
   "outputs": [],
   "source": [
    "# 1024, 1369,\n",
    "def classify_model(input_shape = (256, 256, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    # X = tf.keras.layers.Resizing(pixes,pixes)(X_input)\n",
    "   \n",
    "    X = layers.Rescaling(1./255)(X_input)\n",
    "    \n",
    "    X = Conv2D(filters = 16, kernel_size = 3, strides = (1, 1), padding='valid',activation='relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(1, 1))(X)\n",
    "\n",
    "    # X_shortcut = X\n",
    "    \n",
    "    X = Conv2D(filters = 64, kernel_size = 3, strides = (1, 1), padding='same',activation='relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "\n",
    "    X = Conv2D(filters = 64, kernel_size = 3, strides = (1, 1), padding='valid',activation='relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(1, 1))(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    # X = Add()([X_shortcut,X])\n",
    "    # X = Activation('relu')(X)\n",
    "    # X_shortcut = X\n",
    "    \n",
    "    X = Conv2D(filters = 32, kernel_size = 5, strides = (1, 1), padding='valid',activation='relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(1, 1))(X)\n",
    "\n",
    "    \n",
    "    X = Conv2D(filters = 16, kernel_size = 3, strides = (1, 1), padding='same',activation='relu')(X)\n",
    "    X = MaxPooling2D((4, 4))(X)\n",
    "\n",
    "    # X = Add()([X_shortcut,X])\n",
    "    # X = Activation('relu')(X)\n",
    "    # X_shortcut = X\n",
    "    \n",
    "    X = Conv2D(filters = 16, kernel_size = 3, padding='valid',activation='relu')(X)\n",
    "    X = AveragePooling2D((2,2))(X)\n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(64, activation='relu')(X)\n",
    "    X = Dense(32, activation='relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(16, activation='relu')(X)\n",
    "    X = Dense(5, activation='linear', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIPfBa--AFTX",
    "outputId": "585d6f16-d0e2-4158-f9d6-d85247294362"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMEKA ONWUEPE\\anaconda3\\envs\\homl3\\lib\\site-packages\\keras\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_5 (Rescaling)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 252, 252, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 252, 252, 64)      9280      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 125, 125, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 123, 123, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 121, 121, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 121, 121, 64)      0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 117, 117, 32)      51232     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 115, 115, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 115, 115, 16)      4624      \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 28, 28, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 26, 26, 16)        2320      \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 13, 13, 16)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2704)              0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2704)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                173120    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 280,645\n",
      "Trainable params: 280,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_learning_phase(True)\n",
    "\n",
    "model = classify_model(classes = 5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_1 = np.zeros((252, 252, 16))\n",
    "# d_2 = np.zeros((252, 252, 64))\n",
    "\n",
    "# d_3 = np.zeros((16, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.matmul(d_2, d_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "MTiQgyLMAoTJ"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HsPu5UC_A74A",
    "outputId": "ff822e6b-193a-4b9a-d247-4589a0b58a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "44/44 [==============================] - 369s 7s/step - loss: 1.0559 - accuracy: 0.5573 - val_loss: 1.2479 - val_accuracy: 0.6034\n",
      "Epoch 2/4\n",
      "44/44 [==============================] - 298s 7s/step - loss: 1.0064 - accuracy: 0.6003 - val_loss: 1.1320 - val_accuracy: 0.6034\n",
      "Epoch 3/4\n",
      "44/44 [==============================] - 295s 7s/step - loss: 0.9541 - accuracy: 0.6189 - val_loss: 1.0179 - val_accuracy: 0.6034\n",
      "Epoch 4/4\n",
      "44/44 [==============================] - 310s 7s/step - loss: 0.9271 - accuracy: 0.5931 - val_loss: 1.0058 - val_accuracy: 0.6034\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 4\n",
    "history = model.fit(train_dataset, validation_data=validation_dataset, epochs=initial_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4K3-jMPLwfN"
   },
   "outputs": [],
   "source": [
    "# model.save('/content/drive/MyDrive/classify.h5',save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 872 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = image_dataset_from_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['distorted', 'good', 'not_clear', 'not_result', 'wrong_oreintation']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "NewRandomAccessFile failed to Create/Open: ./good\\dataset_spec.pb : The system cannot find the path specified.\r\n; No such process",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./good\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\homl3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1773\u001b[0m, in \u001b[0;36mDatasetV2.load\u001b[1;34m(path, element_spec, compression, reader_func)\u001b[0m\n\u001b[0;32m   1769\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> load_op ->\u001b[39;00m\n\u001b[0;32m   1770\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   1771\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_op\n\u001b[1;32m-> 1773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1775\u001b[0m \u001b[43m    \u001b[49m\u001b[43melement_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreader_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreader_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\homl3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\load_op.py:33\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(path, element_spec, compression, reader_func)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load\u001b[39m(path, element_spec, compression, reader_func):\n\u001b[1;32m---> 33\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_LoadDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreader_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\homl3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\load_op.py:54\u001b[0m, in \u001b[0;36m_LoadDataset.__init__\u001b[1;34m(self, path, element_spec, compression, reader_func)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     51\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn graph mode the `element_spec` argument must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gfile\u001b[38;5;241m.\u001b[39mGFile(\n\u001b[0;32m     53\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, dataset_ops\u001b[38;5;241m.\u001b[39mDATASET_SPEC_FILENAME), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 54\u001b[0m   encoded_spec \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m struct_pb \u001b[38;5;241m=\u001b[39m nested_structure_coder\u001b[38;5;241m.\u001b[39mstruct_pb2\u001b[38;5;241m.\u001b[39mStructuredValue()\n\u001b[0;32m     56\u001b[0m struct_pb\u001b[38;5;241m.\u001b[39mParseFromString(encoded_spec)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\homl3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:116\u001b[0m, in \u001b[0;36mFileIO.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    105\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the contents of a file as a string.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m  Starts reading from current position in file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m    string if in string (regular) mode.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preread_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    118\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\homl3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:77\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_check_passed:\n\u001b[0;32m     75\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mPermissionDeniedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt open for reading\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_buf \u001b[38;5;241m=\u001b[39m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBufferedInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: ./good\\dataset_spec.pb : The system cannot find the path specified.\r\n; No such process"
     ]
    }
   ],
   "source": [
    "test_dataset.load('./good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset.file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 113s 4s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.6597395 ,  0.96521956, -1.0076818 , -1.7701011 ,  0.6418342 ],\n",
       "       [-2.0591779 ,  1.1569911 , -1.2181765 , -2.1864133 ,  0.8012126 ],\n",
       "       [-1.9549001 ,  1.1191351 , -1.1848466 , -2.0780861 ,  0.7576032 ],\n",
       "       ...,\n",
       "       [-1.9455495 ,  1.1035136 , -1.1561215 , -2.0775    ,  0.76126736],\n",
       "       [-1.7681541 ,  1.0382186 , -1.1046677 , -1.887521  ,  0.6757176 ],\n",
       "       [-1.6000786 ,  0.94149196, -0.9853392 , -1.7094097 ,  0.6157208 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
